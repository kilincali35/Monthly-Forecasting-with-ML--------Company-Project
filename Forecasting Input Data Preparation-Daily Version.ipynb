{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project has the aim of forecasting sales numbers with the help of machine learning algorithms. It has several variations like daily foreast, daiy forecast with zip code details and monthly forecast. \n",
    "\n",
    "Normally, classical statistical approaches are used to forecast time series data. But there are several approaches to use machine learning and deep learning algorithms for this purpose. In this project, I tried to use both of them in my experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First task, and detail of this Jupyter Notebook, is to preprocess the raw data into a suitable ML format. The raw data I acquired was in the tabular form of rows as combination and columns as historical days. For a 4 year timespan, it had about 1500 columns. \n",
    "\n",
    "Initial approach was to transform this input data into a moving months format. Afterwards, adding additional input variables that may be useful for predicting the sales of target month. \n",
    "\n",
    "First of all, raw data format must be in a standard form as code is working in a static way to transform it. There must be the data related to combination of from-to countries and then historical sales date in columnwise order. Days to be forecasted must be included at the end of the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code transforms this columnwise format to a rowwise format. Parametricaly, you choose \"how many past days do you want to include as input columns\". \n",
    "\n",
    "For example, if you want to predict day N and if you choose this parameter as X, you will include all days between N-X/N-1 as input variables to predict day N sales. It is the classical approach of forecasting actually. \n",
    "\n",
    "If we have 1500 days of historical data; for each combination we will have about 1500 rows of input data with this format, each row corresponds to a different day with past X days as inputs to predict that specific day, in a moving pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import re\n",
    "from pandas.tseries.offsets import BDay\n",
    "pd.set_option('display.max_columns',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_excel(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\GerçekleşenGünlükZip - Copy.xlsx', sheet_name = 'Gerçekleşen2')\n",
    "\n",
    "#these are very large files, first i read from excel and write to csv, then read from that csv file.\n",
    "\n",
    "#test.to_csv(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\GerçekleşenGünlükZip.csv', sep='\\t', encoding='utf-8', index = False)\n",
    "test = pd.read_csv(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\GerçekleşenGünlükZip.csv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 659 entries, 13 to 14809\n",
      "Columns: 1767 entries, Servis to lastdays\n",
      "dtypes: float64(1733), int64(29), object(5)\n",
      "memory usage: 8.9+ MB\n",
      "None\n",
      "     Servis Yükleme Ülkesi Yükleme Zip Teslim Ülkesi Teslim Zip  2.01.2015  \\\n",
      "13  İhracat     Yunanistan          18       Polonya         47        0.0   \n",
      "73  İhracat        Türkiye           1       Belçika         50        0.0   \n",
      "75  İhracat        Türkiye           1       Belçika         90        0.0   \n",
      "87  İhracat        Türkiye           1       Almanya         68        0.0   \n",
      "90  İhracat        Türkiye           1       İspanya         08        0.0   \n",
      "\n",
      "    3.01.2015  4.01.2015  5.01.2015  6.01.2015  7.01.2015  8.01.2015  ...  \\\n",
      "13   0.000000        0.0        0.0        0.0        0.0        0.0  ...   \n",
      "73   0.353909        0.0        0.0        0.0        0.0        0.0  ...   \n",
      "75   0.000000        0.0        0.0        0.0        0.0        0.0  ...   \n",
      "87   0.000000        0.0        0.0        0.0        0.0        0.0  ...   \n",
      "90   0.000000        0.0        0.0        0.0        0.0        0.0  ...   \n",
      "\n",
      "    22.10.2019  23.10.2019  24.10.2019  25.10.2019  26.10.2019  27.10.2019  \\\n",
      "13           0           0           0           0           0           0   \n",
      "73           0           0           0           0           0           0   \n",
      "75           0           0           0           0           0           0   \n",
      "87           0           0           0           0           0           0   \n",
      "90           0           0           0           0           0           0   \n",
      "\n",
      "    28.10.2019  29.10.2019  30.10.2019  31.10.2019     zeros   lastdays  \n",
      "13           0           0           0           0  0.800116   7.000000  \n",
      "73           0           0           0           0  0.863663   0.025078  \n",
      "75           0           0           0           0  0.767764   7.722272  \n",
      "87           0           0           0           0  0.805315   2.126894  \n",
      "90           0           0           0           0  0.834200  27.258954  \n",
      "\n",
      "[5 rows x 1767 columns]\n"
     ]
    }
   ],
   "source": [
    "test.replace(np.nan, 0, inplace = True)\n",
    "\n",
    "preddays = 28 #how many days to be predicted\n",
    "param = 28 #moving day number\n",
    "test.iloc[:,-(preddays+1):] = 0\n",
    "\n",
    "#sums a specific value rowwise, then divides by total nb of available columns\n",
    "test['zeros'] = ((test == 0).astype(int).sum(axis=1) - (preddays+1)) / (len(test.columns) - (preddays+1+5))\n",
    "\n",
    "#(df == 0).astype(int) for boolean\n",
    "#df.apply( lambda s : s.value_counts().get(0,0), axis=1) #alternative\n",
    "\n",
    "#total sales for last 4 weeks (+2 is for one extra day column and zeros column)\n",
    "test['lastdays'] = test.iloc[:,-(preddays+56+1+1):-(preddays+1+1)].sum(axis=1)\n",
    "\n",
    "#conditional dataframe filtering according to columns\n",
    "ignored = test[(test['lastdays'] == 0) | (test['zeros'] > 0.90)]\n",
    "\n",
    "test = test[(test['lastdays'] != 0) & (test['zeros'] <= 0.90)]\n",
    "#test = test.iloc[0:20,:]\n",
    "\n",
    "print(test.info())\n",
    "print(test.head(5))\n",
    "\n",
    "test.drop(['lastdays','zeros'], axis = 1, inplace = True)\n",
    "#test = test.drop(['lastdays'], axis = 1)\n",
    "\n",
    "ignored.drop(['lastdays','zeros'], axis=1, inplace = True)\n",
    "#ignored = ignored.drop(['lastdays'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code defines the moving day and days to be predicted parameters. \n",
    "\n",
    "It also calculates total zero sales days from the past and last 2 month total sales. Combinations with rare sales and not very active ones will be filtered from the dataset. Otherwise it will be a huge dataset because of these high 0 percentage combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['service', 'from', 'from_zip', 'to', 'to_zip', 'date', 'D-28', 'D-27', 'D-26', 'D-25', 'D-24', 'D-23', 'D-22', 'D-21', 'D-20', 'D-19', 'D-18', 'D-17', 'D-16', 'D-15', 'D-14', 'D-13', 'D-12', 'D-11', 'D-10', 'D-9', 'D-8', 'D-7', 'D-6', 'D-5', 'D-4', 'D-3', 'D-2', 'D-1', 'D']\n"
     ]
    }
   ],
   "source": [
    "colnum = len(test.columns)\n",
    "rownum = len(test)\n",
    "\n",
    "#list of all columns\n",
    "allcols = list(test.columns.values)\n",
    "\n",
    "# we set the first 6 fixed cols in this list. Then append several others according to param, to the column list\n",
    "cols = ['service', 'from', 'from_zip', 'to', 'to_zip', 'date']\n",
    "for p in range(max(preddays,param)+1):\n",
    "    if p < max(preddays,param):\n",
    "        cols.append('D'+'-'+str(max(preddays,param)-p)) \n",
    "    else:\n",
    "        cols.append('D')\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code sets the column names to be used after transformation of raw data\n",
    "\n",
    "Below code creates lists from raw rowwise data in a moving pattern according to LastN Month parameter. Firstly it sets static columns for that row in each list; then it sets the date parameter then it gets Last N months + day to be predicted. \n",
    "\n",
    "After it completed all operations on raw data rows, dateset is turned into a Dataframe from list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = pd.DataFrame(columns = cols)\n",
    "mid = []\n",
    "outlist = []\n",
    "\n",
    "# this appends lists into a list, output is list of lists. ınner lists are moving historical values with same country combinations, until the end of initial row.         \n",
    "for i in range(rownum):\n",
    "    rowcnt = 0\n",
    "    colcnt = 0\n",
    "    shift = 0\n",
    "    for j in range(colnum - max(preddays,param) - 5):\n",
    "        while colcnt < 5:\n",
    "            mid.append(test.iloc[i,colcnt])\n",
    "            colcnt = colcnt + 1\n",
    "        if colcnt == 5:\n",
    "            mid.append(allcols[colcnt+j+max(preddays,param)]) #it gets the column name of prediction day from column list\n",
    "            colcnt = colcnt + 1\n",
    "        for m in range(5+shift,5+max(preddays,param)+shift+1):\n",
    "                if m < 5 + max(preddays,param) + shift:\n",
    "                    mid.append(test.iloc[i,m])\n",
    "                else:\n",
    "                    mid.append(test.iloc[i,m]) \n",
    "        shift = shift + 1\n",
    "        rowcnt = rowcnt + 1\n",
    "        colcnt = 0\n",
    "        outlist.append(mid)\n",
    "        mid = []\n",
    "\n",
    "#making a dataframe from list of lists\n",
    "out = pd.DataFrame(outlist, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['date'] = pd.to_datetime(out['date'], format = '%d.%m.%Y') #this one transforms to yyyy mm dd format in default. datetime type cannot be converted into mm - yyyyy\n",
    "#out['date'] = out['date'].dt.to_period('m') # this one converts datetime type into period format and it is shown as yyyy mm\n",
    "#out['date2'] = out['date'].dt.strftime('%m-%Y') #this one converts it into a string object which is shown as mm yyyy\n",
    "\n",
    "out['year'] = out['date'].dt.year.astype(str)\n",
    "out['quarter'] = out['date'].dt.quarter.astype(str)\n",
    "out['month'] = out['date'].dt.month.astype(str)\n",
    "out['week'] = out['date'].dt.week.astype(str)\n",
    "out['day'] = out['date'].dt.day.astype(str)\n",
    "out['weekday'] = out['date'].dt.weekday.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntdict = pd.read_excel(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\Gerçekleşen.xlsx', sheet_name = 'CountryCode') #dataframe with 2 columns ;country vs code\n",
    "cntdict = dict(zip(cntdict['CNT'], cntdict['CODE'])) # transforming it into a dictionary\n",
    "\n",
    "out['from'] = out['from'].map(cntdict) #change a column with help of dictionary keys, return values\n",
    "out['to'] = out['to'].map(cntdict)\n",
    "\n",
    "cntlist = np.unique(out[['from', 'to']].values.ravel('K')) #get the unique values list from multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code transforms country names to country codes from a dictionary\n",
    "\n",
    "Below code calculates moving averages for each row, they will also be used as inputs for prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1141388 entries, 0 to 1141387\n",
      "Data columns (total 45 columns):\n",
      "service     1141388 non-null object\n",
      "from        1141388 non-null object\n",
      "from_zip    1141388 non-null object\n",
      "to          1141388 non-null object\n",
      "to_zip      1141388 non-null object\n",
      "date        1141388 non-null datetime64[ns]\n",
      "D-28        1141388 non-null float64\n",
      "D-27        1141388 non-null float64\n",
      "D-26        1141388 non-null float64\n",
      "D-25        1141388 non-null float64\n",
      "D-24        1141388 non-null float64\n",
      "D-23        1141388 non-null float64\n",
      "D-22        1141388 non-null float64\n",
      "D-21        1141388 non-null float64\n",
      "D-20        1141388 non-null float64\n",
      "D-19        1141388 non-null float64\n",
      "D-18        1141388 non-null float64\n",
      "D-17        1141388 non-null float64\n",
      "D-16        1141388 non-null float64\n",
      "D-15        1141388 non-null float64\n",
      "D-14        1141388 non-null float64\n",
      "D-13        1141388 non-null float64\n",
      "D-12        1141388 non-null float64\n",
      "D-11        1141388 non-null float64\n",
      "D-10        1141388 non-null float64\n",
      "D-9         1141388 non-null float64\n",
      "D-8         1141388 non-null float64\n",
      "D-7         1141388 non-null float64\n",
      "D-6         1141388 non-null float64\n",
      "D-5         1141388 non-null float64\n",
      "D-4         1141388 non-null float64\n",
      "D-3         1141388 non-null float64\n",
      "D-2         1141388 non-null float64\n",
      "D-1         1141388 non-null float64\n",
      "D           1141388 non-null float64\n",
      "year        1141388 non-null object\n",
      "quarter     1141388 non-null object\n",
      "month       1141388 non-null object\n",
      "week        1141388 non-null object\n",
      "day         1141388 non-null object\n",
      "weekday     1141388 non-null object\n",
      "moving7     1141388 non-null float64\n",
      "moving14    1141388 non-null float64\n",
      "moving21    1141388 non-null float64\n",
      "moving28    1141388 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(33), object(11)\n",
      "memory usage: 391.9+ MB\n",
      "   service from from_zip  to to_zip       date  D-28  D-27  D-26  D-25  D-24  \\\n",
      "0  İhracat   GR       18  PL     47 2015-01-30   0.0   0.0   0.0   0.0   0.0   \n",
      "1  İhracat   GR       18  PL     47 2015-01-31   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "   D-23  D-22  D-21  D-20  D-19  D-18  D-17  D-16  D-15  D-14  D-13  D-12  \\\n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "   D-11  D-10  D-9  D-8  D-7  D-6  D-5  D-4  D-3  D-2  D-1    D  year quarter  \\\n",
      "0   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2015       1   \n",
      "1   0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2015       1   \n",
      "\n",
      "  month week day weekday  moving7  moving14  moving21  moving28  \n",
      "0     1    5  30       4      0.0       0.0       0.0       0.0  \n",
      "1     1    5  31       5      0.0       0.0       0.0       0.0  \n",
      "RangeIndex(start=0, stop=1141388, step=1)\n"
     ]
    }
   ],
   "source": [
    "for i in [7,14,21,28]:\n",
    "    movinglist = []\n",
    "    for col in out.columns:\n",
    "    \n",
    "        if ('D-' in col):\n",
    "        \n",
    "            if (int(re.findall('\\d+', col)[0])) <= i:\n",
    "                movinglist.append(col)\n",
    "    if param >= i:\n",
    "        out['moving'+str(i)] = (out[movinglist].sum(axis=1))/i\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "out.info()\n",
    "print(out.head(2))\n",
    "print(out.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code gets historical Eur/TL and USD/TL prices from another table, makes required transformations for date variables and then joins them to the main prediction table as input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2192 entries, 0 to 2191\n",
      "Data columns (total 8 columns):\n",
      "Tarih      2192 non-null datetime64[ns]\n",
      "Dolar      2192 non-null float64\n",
      "Euro       2192 non-null float64\n",
      "Pound      1669 non-null float64\n",
      "month      2192 non-null object\n",
      "quarter    2192 non-null object\n",
      "year       2192 non-null object\n",
      "day        2192 non-null object\n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 137.1+ KB\n",
      "Index(['service', 'from', 'from_zip', 'to', 'to_zip', 'date', 'D-28', 'D-27',\n",
      "       'D-26', 'D-25', 'D-24', 'D-23', 'D-22', 'D-21', 'D-20', 'D-19', 'D-18',\n",
      "       'D-17', 'D-16', 'D-15', 'D-14', 'D-13', 'D-12', 'D-11', 'D-10', 'D-9',\n",
      "       'D-8', 'D-7', 'D-6', 'D-5', 'D-4', 'D-3', 'D-2', 'D-1', 'D', 'year',\n",
      "       'quarter', 'month', 'week', 'day', 'weekday', 'moving7', 'moving14',\n",
      "       'moving21', 'moving28', 'Dolar', 'Euro'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',25)\n",
    "\n",
    "kur = pd.read_excel(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\Gerçekleşen.xlsx', sheet_name = 'Kurlar')\n",
    "\n",
    "kur.drop(['Gün'], axis = 1, inplace =True)\n",
    "\n",
    "#forward fill for specific columns and all rows\n",
    "kur.loc[:,['Dolar', 'Euro']] = kur.loc[:,['Dolar', 'Euro']].ffill(axis = 0)\n",
    "kur.loc[:,['Dolar', 'Euro']] = kur.loc[:,['Dolar', 'Euro']].bfill(axis = 0)\n",
    "\n",
    "#getting time values from datetime object\n",
    "kur['month'] = kur['Tarih'].dt.month.astype(str)\n",
    "kur['quarter'] = kur['Tarih'].dt.quarter.astype(str)\n",
    "kur['year'] = kur['Tarih'].dt.year.astype(str)\n",
    "kur['day'] = kur['Tarih'].dt.day.astype(str)\n",
    "\n",
    "#kur['Dolar'] = kur.groupby(['Tarih'])['Dolar'].mean()\n",
    "#normally groupby changes the structure of dataframe and output is summary table, only grouped columns and aggregation\n",
    "#but transfrom changes it, uses the same data structure. !!!!\n",
    "\n",
    "##kur['Dolar'] = kur.groupby('Tarih')['Dolar'].transform(np.mean)\n",
    "##kur['Euro'] = kur.groupby('Tarih')['Euro'].transform(np.mean)\n",
    "##kur['Pound'] = kur.groupby('Tarih')['Pound'].transform(np.mean)\n",
    "\n",
    "kur.drop_duplicates(inplace=True)\n",
    "kur.reset_index(inplace=True, drop=True)\n",
    "\n",
    "kur.info()\n",
    "\n",
    "#joining two tables, selecting only specific columns from right table, join on multiple columns.\n",
    "final = pd.merge(out, kur[['Dolar', 'Euro', 'day', 'month', 'year']], how = 'left', on = ['day', 'month', 'year'])\n",
    "print(final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     COUNTRY_CODE    HOLIDAY day  weekday month  year  holidaycnt\n",
      "1500           TR 2015-01-01   1        3     1  2015           1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_columns',25)\n",
    "\n",
    "holiday = pd.read_excel(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\tatiller.xlsx', sheet_name = 'Tatiller')\n",
    "\n",
    "holiday['HOLIDAY'] = pd.to_datetime(holiday['HOLIDAY'], format = '%d/%m/%Y')\n",
    "\n",
    "holiday['day'] = holiday['HOLIDAY'].dt.day.astype(str)\n",
    "holiday['weekday'] = holiday['HOLIDAY'].dt.weekday\n",
    "holiday['month'] = holiday['HOLIDAY'].dt.month.astype(str)\n",
    "holiday['year'] = holiday['HOLIDAY'].dt.year.astype(str)\n",
    "\n",
    "#case when structure basically, if holiday value is x then set 1 else 0\n",
    "#holiday['isfriday1'] = np.where(holiday['weekday'] == 5, 1,0)\n",
    "\n",
    "#I wanted to count FRİDAYS according to partition. i found a way by flagging fridays above. Then sum these flags over partition. Transform was required to hold original table\n",
    "#holiday['fridaycnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['isfriday1'].transform(np.sum)\n",
    "\n",
    "#holiday['cnt'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'], as_index = False).size().relset_index(name='cnt')['cnt']\n",
    "#groupby ile yapılan aggregation işlemleri özet tabloyu getiriyor. as_index yapınca değerlerin index olmasını engelliyorsun. size fonksiyonu count alıyor, bu grupta kaç satır var gibi.\n",
    "#reset index de aldığın count için sütun açmanı sağlıyor. gelen sonuç groupby içindeki 3 sütunu ve sonuç sütununu içeriyor, yani 4 sütunlu bir dataframe\n",
    "#istediğimiz tek bir sütun olduğu için de o dataframe içinden ilgilendiğiöiz sütunu çekerek eşliyoruz. Ama transform gerektiği için bu yapıyı kullanmadık\n",
    "\n",
    "\n",
    "#holiday table shows holidays rowwise. This line counts total holidays per month\n",
    "holiday['holidaycnt'] = holiday.groupby(['COUNTRY_CODE', 'month','year'])['COUNTRY_CODE'].transform('count')\n",
    "\n",
    "#transfrom ile yapınca groupbyda yapılan özetleme işlemine girmiyor, tüm satırlara duplike de olsa aggregate değerlerini getiriyor. \n",
    "print(holiday[holiday['COUNTRY_CODE'] == 'TR'].sort_values(by=['COUNTRY_CODE', 'year','month']).head(1))\n",
    "\n",
    "holiday.sort_values(by=['COUNTRY_CODE', 'year', 'month'])\n",
    "\n",
    "holiday['is_big'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above table gets national holidays from an external table, makes some aggregations and transformations. These holidays will be calculated for each from-to country and will be used as inputs for prediction. Below code calculates holiday types. If an holiday is just one day, it is small holiday. If it has consequent days, it is big. \n",
    "\n",
    "For a big holiday; we look at previous and next work week and count the number of holidays. \n",
    "\n",
    "For a small holiday, we count the holidays inside 3 business day range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ali.kilinc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\ali.kilinc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\ali.kilinc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  COUNTRY_CODE    HOLIDAY day  weekday month  year  holidaycnt  is_big\n",
      "0          AFG 2018-03-21  21        2     3  2018           1     0.0\n",
      "1           AT 2015-01-01   1        3     1  2015           1     0.0\n",
      "2           AT 2015-01-06   6        1     1  2015           1     0.0\n",
      "3           AT 2015-04-06   6        0     4  2015           1     0.0\n",
      "4           AT 2015-05-01   1        4     5  2015           1     0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(holiday)):\n",
    "    \n",
    "    #for each holiday row, this will bring the +1-1 business day range, then i will count it countrywise\n",
    "    #loc and iloc i will get same results for a full dataset. \n",
    "    #But for a sub dataset, loc will get original index position, whereas iloc will get sub table position ıf the i\n",
    "    sub = holiday[((holiday['HOLIDAY'] < (holiday.loc[i,'HOLIDAY'] + BDay(2))) & (holiday['HOLIDAY'] > (holiday.loc[i,'HOLIDAY'] - BDay(2))))\\\n",
    "                  &(~holiday['day'].isin([5,6]))]\n",
    "    \n",
    "    subshrt = holiday[((holiday['HOLIDAY'] < (holiday.loc[i,'HOLIDAY'] + BDay(3)))\\\n",
    "                     & (holiday['HOLIDAY'] > (holiday.loc[i,'HOLIDAY'] - BDay(3))))\\\n",
    "                     & (~holiday['day'].isin([5,6]))]\n",
    "    \n",
    "    sublong = holiday[((holiday['HOLIDAY'] <= (holiday.loc[i,'HOLIDAY'] + dt.timedelta(days = 11)))\\\n",
    "                     & (holiday['HOLIDAY'] >= (holiday.loc[i,'HOLIDAY'] - dt.timedelta(days = 7))))\\\n",
    "                     &(~holiday['day'].isin([5,6]))]\n",
    "    \n",
    "    sub['holiday_cnt'] = sub.groupby(['COUNTRY_CODE'])['HOLIDAY'].transform('count')\n",
    "    subshrt['holiday_cnt'] = subshrt.groupby(['COUNTRY_CODE'])['HOLIDAY'].transform('count')\n",
    "    sublong['holiday_cnt'] = sublong.groupby(['COUNTRY_CODE'])['HOLIDAY'].transform('count')\n",
    "    \n",
    "    holiday.loc[i,'is_big'] = np.where(sub.loc[i,'holiday_cnt'] >= 2, 1, 0)\n",
    "    holiday.at[i, 'holidaycnt'] = np.where(holiday.loc[i, 'is_big'] == 0, subshrt.loc[i, 'holiday_cnt'], sublong.loc[i, 'holiday_cnt'])\n",
    "\n",
    "print(holiday.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day', 'month', 'year'], dtype='object')\n",
      "  day month  year\n",
      "0   1     1  2015\n",
      "1   2     1  2015\n",
      "2   3     1  2015\n",
      "3   4     1  2015\n",
      "4   5     1  2015\n",
      "5   6     1  2015\n",
      "6   7     1  2015\n",
      "7   8     1  2015\n",
      "8   9     1  2015\n",
      "9  10     1  2015\n",
      "Index(['COUNTRY_CODE', 'key', 'day', 'month', 'year'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#This creates a full schedule to calculate fridays for each month historically\n",
    "dat = pd.date_range(start = '1/1/2015', end='12/12/2020')\n",
    "\n",
    "dat = pd.DataFrame(dat, columns = ['date'])\n",
    "\n",
    "dat['day'] = dat['date'].dt.day.astype(str)\n",
    "dat['month'] = dat['date'].dt.month.astype(str)\n",
    "dat['year'] = dat['date'].dt.year.astype(str)\n",
    "dat['weekday'] = dat['date'].dt.weekday\n",
    "\n",
    "dat['isfriday2'] = np.where(dat['weekday'] ==5, 1,0)\n",
    "dat['fridaycnt2'] = dat.groupby(['month', 'year'], as_index = False)['isfriday2'].transform(np.sum)\n",
    "\n",
    "dat.drop(columns = ['date', 'weekday','isfriday2', 'fridaycnt2'], inplace = True)\n",
    "dat.drop_duplicates(inplace=True)\n",
    "dat.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(dat.columns)\n",
    "print(dat.head(10))\n",
    "\n",
    "\n",
    "\n",
    "#this part cross joins country list with monthly friday table. Creates full schedule for each country in list\n",
    "countries = cntlist\n",
    "cnt = pd.DataFrame(countries, columns = ['COUNTRY_CODE'])\n",
    "\n",
    "#there is not a common column for both tables. We created a fictional column to join\n",
    "dat['key'] = 1\n",
    "cnt['key'] = 1\n",
    "\n",
    "all = pd.merge(cnt, dat, how = 'outer', on='key')\n",
    "print(all.columns)\n",
    "\n",
    "all.drop(columns = ['key'], inplace = True)\n",
    "dat.drop(columns = ['key'], inplace = True)\n",
    "cnt.drop(columns = ['key'], inplace = True)\n",
    "\n",
    "#this part merges all countries and monthly fridays table with holiday table via left join, so that we can see them integrated. \n",
    "all = pd.merge(all, holiday[['COUNTRY_CODE', 'HOLIDAY', 'day', 'weekday', 'month', 'year', 'holidaycnt', 'is_big']], \n",
    "               how = 'left', left_on = ['COUNTRY_CODE', 'day', 'month', 'year'], right_on = ['COUNTRY_CODE', 'day', 'month', 'year'])\n",
    "all.drop_duplicates(inplace=True)\n",
    "all.replace(np.nan, 0, inplace = True)\n",
    "all.drop(columns = ['weekday','HOLIDAY'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code is normally constructed for monthly predition dataset. It creates a full schedule for 5 years, counts each workday inside a month etc.(code below for example) Then it counts workdays and holidays for each different day for each country to calculate work tueasdays for october for Greece as an example. It is not mainly used for daily version, but I kept it for a possible use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Full code for monthly version calculations\\n#case when structure basically, if holiday value is x then set 1 else 0\\nholiday['ismon1'] = np.where(holiday['weekday'] == 1, 1,0)\\nholiday['istue1'] = np.where(holiday['weekday'] == 2, 1,0)\\nholiday['iswed1'] = np.where(holiday['weekday'] == 3, 1,0)\\nholiday['isthurs1'] = np.where(holiday['weekday'] == 4, 1,0)\\nholiday['isfriday1'] = np.where(holiday['weekday'] == 5, 1,0)\\n\\n\\n#I wanted to count FRİDAYS according to partition. i found a way by flagging fridays above. Then sum these flags over partition. Transform was required to hold original table\\nholiday['moncnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['ismon1'].transform(np.sum)\\nholiday['tuecnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['istue1'].transform(np.sum)\\nholiday['wedcnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['iswed1'].transform(np.sum)\\nholiday['thurscnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['isthurs1'].transform(np.sum)\\nholiday['fridaycnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['isfriday1'].transform(np.sum)\\n\\n#holiday table shows holidays rowwise. This line counts total holidays per month\\nholiday['holidaycnt'] = holiday.groupby(['COUNTRY_CODE', 'month','year'])['COUNTRY_CODE'].transform('count')\\n\\n#transfrom ile yapınca groupbyda yapılan özetleme işlemine girmiyor, tüm satırlara duplike de olsa aggregate değerlerini getiriyor. \\nprint(holiday[holiday['COUNTRY_CODE'] == 'TR'].sort_values(by=['COUNTRY_CODE', 'year','month']).head(100))\\n\\n#This creates a full schedule to calculate fridays for each month historically\\ndat = pd.date_range(start = '1/1/2015', end='12/12/2020')\\n\\ndat = pd.DataFrame(dat, columns = ['date'])\\n\\ndat['month'] = dat['date'].dt.month.astype(str)\\ndat['year'] = dat['date'].dt.year.astype(str)\\ndat['weekday'] = dat['date'].dt.weekday\\n\\ndat['ismon2'] = np.where(dat['weekday'] ==1, 1,0)\\ndat['istue2'] = np.where(dat['weekday'] ==2, 1,0)\\ndat['iswed2'] = np.where(dat['weekday'] ==3, 1,0)\\ndat['isthurs2'] = np.where(dat['weekday'] ==4, 1,0)\\ndat['isfriday2'] = np.where(dat['weekday'] ==5, 1,0)\\n\\n\\ndat['moncnt2'] = dat.groupby(['month', 'year'], as_index = False)['ismon2'].transform(np.sum)\\ndat['tuecnt2'] = dat.groupby(['month', 'year'], as_index = False)['istue2'].transform(np.sum)\\ndat['wedcnt2'] = dat.groupby(['month', 'year'], as_index = False)['iswed2'].transform(np.sum)\\ndat['thurscnt2'] = dat.groupby(['month', 'year'], as_index = False)['isthurs2'].transform(np.sum)\\ndat['fridaycnt2'] = dat.groupby(['month', 'year'], as_index = False)['isfriday2'].transform(np.sum)\\n\\ndat.drop(columns=['date', 'weekday','isfriday2', 'isthurs2', 'iswed2', 'istue2', 'ismon2'], inplace = True)\\ndat.drop_duplicates(inplace=True)\\ndat.reset_index(inplace=True, drop=True)\\n\\n#this part cross joins country list with monthly friday table. Creates full schedule for each country in list\\ncountries = cntlist\\ncnt = pd.DataFrame(countries, columns = ['COUNTRY_CODE'])\\n\\n#there is not a common column for both tables. We created a fictional column to join\\ndat['key'] = 1\\ncnt['key'] = 1\\n\\nall = pd.merge(cnt, dat, how = 'outer', on='key')\\n\\nall.drop(columns = ['key'], inplace = True)\\ndat.drop(columns = ['key'], inplace = True)\\ncnt.drop(columns = ['key'], inplace = True)\\n\\n#this part merges all countries and monthly fridays table with holiday table via left join, so that we can see them integrated. \\nall = pd.merge(all, holiday[['COUNTRY_CODE', 'month', 'year','moncnt1', 'tuecnt1', 'wedcnt1', 'thurscnt1', 'fridaycnt1', 'holidaycnt']], \\n               how = 'left', left_on = ['COUNTRY_CODE', 'month', 'year'], right_on = ['COUNTRY_CODE', 'month', 'year'])\\n\\nall.drop_duplicates(inplace=True)\\nall.replace(np.nan, 0, inplace = True)\\n\\nall['moncnt'] = all['moncnt2'] - all['moncnt1']\\nall['tuecnt'] = all['tuecnt2'] - all['tuecnt1']\\nall['wedcnt'] = all['wedcnt2'] - all['wedcnt1']\\nall['thurscnt'] = all['thurscnt2'] - all['thurscnt1']\\nall['fridaycnt'] = all['fridaycnt2'] - all['fridaycnt1'] #count of work fridays, some fridays may intersect with holiday fridays\\n\\nall.drop(columns = ['fridaycnt2', 'fridaycnt1', 'thurscnt2', 'thurscnt1', 'wedcnt2', 'wedcnt1', 'tuecnt2', 'tuecnt1', 'moncnt2', 'moncnt1'], inplace = True)\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Full code for monthly version calculations\n",
    "#case when structure basically, if holiday value is x then set 1 else 0\n",
    "holiday['ismon1'] = np.where(holiday['weekday'] == 1, 1,0)\n",
    "holiday['istue1'] = np.where(holiday['weekday'] == 2, 1,0)\n",
    "holiday['iswed1'] = np.where(holiday['weekday'] == 3, 1,0)\n",
    "holiday['isthurs1'] = np.where(holiday['weekday'] == 4, 1,0)\n",
    "holiday['isfriday1'] = np.where(holiday['weekday'] == 5, 1,0)\n",
    "\n",
    "\n",
    "#I wanted to count FRİDAYS according to partition. i found a way by flagging fridays above. Then sum these flags over partition. Transform was required to hold original table\n",
    "holiday['moncnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['ismon1'].transform(np.sum)\n",
    "holiday['tuecnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['istue1'].transform(np.sum)\n",
    "holiday['wedcnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['iswed1'].transform(np.sum)\n",
    "holiday['thurscnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['isthurs1'].transform(np.sum)\n",
    "holiday['fridaycnt1'] = holiday.groupby(['COUNTRY_CODE', 'month', 'year'])['isfriday1'].transform(np.sum)\n",
    "\n",
    "#holiday table shows holidays rowwise. This line counts total holidays per month\n",
    "holiday['holidaycnt'] = holiday.groupby(['COUNTRY_CODE', 'month','year'])['COUNTRY_CODE'].transform('count')\n",
    "\n",
    "#transfrom ile yapınca groupbyda yapılan özetleme işlemine girmiyor, tüm satırlara duplike de olsa aggregate değerlerini getiriyor. \n",
    "print(holiday[holiday['COUNTRY_CODE'] == 'TR'].sort_values(by=['COUNTRY_CODE', 'year','month']).head(100))\n",
    "\n",
    "#This creates a full schedule to calculate fridays for each month historically\n",
    "dat = pd.date_range(start = '1/1/2015', end='12/12/2020')\n",
    "\n",
    "dat = pd.DataFrame(dat, columns = ['date'])\n",
    "\n",
    "dat['month'] = dat['date'].dt.month.astype(str)\n",
    "dat['year'] = dat['date'].dt.year.astype(str)\n",
    "dat['weekday'] = dat['date'].dt.weekday\n",
    "\n",
    "dat['ismon2'] = np.where(dat['weekday'] ==1, 1,0)\n",
    "dat['istue2'] = np.where(dat['weekday'] ==2, 1,0)\n",
    "dat['iswed2'] = np.where(dat['weekday'] ==3, 1,0)\n",
    "dat['isthurs2'] = np.where(dat['weekday'] ==4, 1,0)\n",
    "dat['isfriday2'] = np.where(dat['weekday'] ==5, 1,0)\n",
    "\n",
    "\n",
    "dat['moncnt2'] = dat.groupby(['month', 'year'], as_index = False)['ismon2'].transform(np.sum)\n",
    "dat['tuecnt2'] = dat.groupby(['month', 'year'], as_index = False)['istue2'].transform(np.sum)\n",
    "dat['wedcnt2'] = dat.groupby(['month', 'year'], as_index = False)['iswed2'].transform(np.sum)\n",
    "dat['thurscnt2'] = dat.groupby(['month', 'year'], as_index = False)['isthurs2'].transform(np.sum)\n",
    "dat['fridaycnt2'] = dat.groupby(['month', 'year'], as_index = False)['isfriday2'].transform(np.sum)\n",
    "\n",
    "dat.drop(columns=['date', 'weekday','isfriday2', 'isthurs2', 'iswed2', 'istue2', 'ismon2'], inplace = True)\n",
    "dat.drop_duplicates(inplace=True)\n",
    "dat.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#this part cross joins country list with monthly friday table. Creates full schedule for each country in list\n",
    "countries = cntlist\n",
    "cnt = pd.DataFrame(countries, columns = ['COUNTRY_CODE'])\n",
    "\n",
    "#there is not a common column for both tables. We created a fictional column to join\n",
    "dat['key'] = 1\n",
    "cnt['key'] = 1\n",
    "\n",
    "all = pd.merge(cnt, dat, how = 'outer', on='key')\n",
    "\n",
    "all.drop(columns = ['key'], inplace = True)\n",
    "dat.drop(columns = ['key'], inplace = True)\n",
    "cnt.drop(columns = ['key'], inplace = True)\n",
    "\n",
    "#this part merges all countries and monthly fridays table with holiday table via left join, so that we can see them integrated. \n",
    "all = pd.merge(all, holiday[['COUNTRY_CODE', 'month', 'year','moncnt1', 'tuecnt1', 'wedcnt1', 'thurscnt1', 'fridaycnt1', 'holidaycnt']], \n",
    "               how = 'left', left_on = ['COUNTRY_CODE', 'month', 'year'], right_on = ['COUNTRY_CODE', 'month', 'year'])\n",
    "\n",
    "all.drop_duplicates(inplace=True)\n",
    "all.replace(np.nan, 0, inplace = True)\n",
    "\n",
    "all['moncnt'] = all['moncnt2'] - all['moncnt1']\n",
    "all['tuecnt'] = all['tuecnt2'] - all['tuecnt1']\n",
    "all['wedcnt'] = all['wedcnt2'] - all['wedcnt1']\n",
    "all['thurscnt'] = all['thurscnt2'] - all['thurscnt1']\n",
    "all['fridaycnt'] = all['fridaycnt2'] - all['fridaycnt1'] #count of work fridays, some fridays may intersect with holiday fridays\n",
    "\n",
    "all.drop(columns = ['fridaycnt2', 'fridaycnt1', 'thurscnt2', 'thurscnt1', 'wedcnt2', 'wedcnt1', 'tuecnt2', 'tuecnt1', 'moncnt2', 'moncnt1'], inplace = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code joins all sub table into a final one, which will be used as an input table for main algorithm. Then it is written as csv as an input for algorithm and xlsx for analysing the output manully for a quick basic inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service', 'from', 'from_zip', 'to', 'to_zip', 'date', 'D-28', 'D-27',\n",
      "       'D-26', 'D-25', 'D-24', 'D-23', 'D-22', 'D-21', 'D-20', 'D-19', 'D-18',\n",
      "       'D-17', 'D-16', 'D-15', 'D-14', 'D-13', 'D-12', 'D-11', 'D-10', 'D-9',\n",
      "       'D-8', 'D-7', 'D-6', 'D-5', 'D-4', 'D-3', 'D-2', 'D-1', 'D', 'year',\n",
      "       'quarter', 'month', 'week', 'day', 'weekday', 'moving7', 'moving14',\n",
      "       'moving21', 'moving28', 'Dolar', 'Euro', 'COUNTRY_CODE', 'holidaycnt',\n",
      "       'is_big'],\n",
      "      dtype='object')\n",
      "Index(['service', 'from', 'from_zip', 'to', 'to_zip', 'date', 'D-28', 'D-27',\n",
      "       'D-26', 'D-25', 'D-24', 'D-23', 'D-22', 'D-21', 'D-20', 'D-19', 'D-18',\n",
      "       'D-17', 'D-16', 'D-15', 'D-14', 'D-13', 'D-12', 'D-11', 'D-10', 'D-9',\n",
      "       'D-8', 'D-7', 'D-6', 'D-5', 'D-4', 'D-3', 'D-2', 'D-1', 'D', 'year',\n",
      "       'quarter', 'month', 'week', 'day', 'weekday', 'moving7', 'moving14',\n",
      "       'moving21', 'moving28', 'Dolar', 'Euro', 'dptholidaycnt', 'dpt_is_big',\n",
      "       'arvholidaycnt', 'arv_is_big'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1141388 entries, 0 to 1141387\n",
      "Data columns (total 51 columns):\n",
      "service          1141388 non-null object\n",
      "from             1141388 non-null object\n",
      "from_zip         1141388 non-null object\n",
      "to               1141388 non-null object\n",
      "to_zip           1141388 non-null object\n",
      "date             1141388 non-null datetime64[ns]\n",
      "D-28             1141388 non-null float64\n",
      "D-27             1141388 non-null float64\n",
      "D-26             1141388 non-null float64\n",
      "D-25             1141388 non-null float64\n",
      "D-24             1141388 non-null float64\n",
      "D-23             1141388 non-null float64\n",
      "D-22             1141388 non-null float64\n",
      "D-21             1141388 non-null float64\n",
      "D-20             1141388 non-null float64\n",
      "D-19             1141388 non-null float64\n",
      "D-18             1141388 non-null float64\n",
      "D-17             1141388 non-null float64\n",
      "D-16             1141388 non-null float64\n",
      "D-15             1141388 non-null float64\n",
      "D-14             1141388 non-null float64\n",
      "D-13             1141388 non-null float64\n",
      "D-12             1141388 non-null float64\n",
      "D-11             1141388 non-null float64\n",
      "D-10             1141388 non-null float64\n",
      "D-9              1141388 non-null float64\n",
      "D-8              1141388 non-null float64\n",
      "D-7              1141388 non-null float64\n",
      "D-6              1141388 non-null float64\n",
      "D-5              1141388 non-null float64\n",
      "D-4              1141388 non-null float64\n",
      "D-3              1141388 non-null float64\n",
      "D-2              1141388 non-null float64\n",
      "D-1              1141388 non-null float64\n",
      "D                1141388 non-null float64\n",
      "year             1141388 non-null object\n",
      "quarter          1141388 non-null object\n",
      "month            1141388 non-null object\n",
      "week             1141388 non-null object\n",
      "day              1141388 non-null object\n",
      "weekday          1141388 non-null object\n",
      "moving7          1141388 non-null float64\n",
      "moving14         1141388 non-null float64\n",
      "moving21         1141388 non-null float64\n",
      "moving28         1141388 non-null float64\n",
      "Dolar            1141388 non-null float64\n",
      "Euro             1141388 non-null float64\n",
      "dptholidaycnt    1141388 non-null float64\n",
      "dpt_is_big       1141388 non-null float64\n",
      "arvholidaycnt    1141388 non-null float64\n",
      "arv_is_big       1141388 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(39), object(11)\n",
      "memory usage: 452.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final = pd.merge(final, all, how = 'left', left_on = ['from', 'day', 'month', 'year'], right_on = ['COUNTRY_CODE', 'day', 'month','year'])\n",
    "print(final.columns)\n",
    "\n",
    "final.drop(columns = ['COUNTRY_CODE'], inplace = True)\n",
    "\n",
    "final.rename(columns = {'holidaycnt':'dptholidaycnt', 'is_big':'dpt_is_big', 'fridaycnt': 'dptfridaycnt', 'thurscnt' : 'dptthurscnt', 'wedcnt': 'dptwedcnt', \n",
    "                        'tuecnt': 'dpttuecnt', 'moncnt':'dptmoncnt'}, inplace = True)\n",
    "\n",
    "final = pd.merge(final, all, how = 'left', left_on = ['to', 'day', 'month', 'year'], right_on = ['COUNTRY_CODE', 'day', 'month', 'year'])\n",
    "\n",
    "\n",
    "\n",
    "final.drop(columns = ['COUNTRY_CODE'], inplace = True)\n",
    "\n",
    "final.rename(columns = {'holidaycnt':'arvholidaycnt', 'is_big':'arv_is_big', 'fridaycnt':'arvfridaycnt', 'thurscnt': 'arvthurscnt', 'wedcnt': 'arvwedcnt',\n",
    "                        'tuecnt':'arvtuecnt', 'moncnt':'arvmoncnt'}, inplace = True)\n",
    "print(final.columns)\n",
    "print(final.info())\n",
    "\n",
    "\n",
    "#print_excel = final.to_excel(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\MovGünlükPrepForecastCompany28.xlsx', index = None, header = True, sheet_name = 'FullTable')\n",
    "#print_csv = final.to_csv(r'C:\\Users\\ali.kilinc\\Desktop\\Tahminleme\\MovGünlükPrepForecastCompany28.csv', index = None, header = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial filters, combination size decreased to 650. Apllying the transformation to this input resulted in a table of 1100K rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
